---
layout:     post   				    # 使用的布局（不需要改）
title:      人工智能伦理 03：哲学与伦理   	# 标题 
subtitle:   墨尔本大学 COMP90087 课程笔记 #副标题
date:       2021-06-04				# 时间
author:     YEY 						# 作者
header-img: img/post-bg-unimelb.png 	#这篇文章标题背景图片
catalog: true 						# 是否归档
mathjax: true                       # 是否启用 MathJax
tags:								#标签
    - 人工智能伦理
    - COMP90087
    - 课程笔记
---

# Module 03 哲学与伦理

## 1. 概览

**人工智能？ 它会带来什么好处或坏处？**

**AI 正面影响的例子：**

* 提高我们的日常生活效率
* 减少重复性的人力劳动
* 减少人为决策的偏见
* 协助新的科学发现
* 更好地解决犯罪、贫困、饥饿、疾病；寻找失踪人员；改善粮食供应、人道主义危机、环境

**AI 负面影响的例子：**

* 增加对弱势/被压迫群体的歧视
* 扩大并加剧现有的不平等
* 减少就业
* 危害环境
* 减少隐私
* 增加功率不对称
* 增加战争风险

## 2. 阅读 "The Ethics of AI Ethics" By Thilo Hagendorff

### 2.1 道德伦理：这有什么好处？

* 伦理有用吗？
* 伦理准则有用吗？
* 还是监管对于确保良好结果和让人们承担责任更重要？
* 是否应该向所有计算机科学家教授伦理学？

### 2.2 主要的 AI 伦理准则

**高引用率的原则：**

* 隐私（Privacy）
* 公平/公正（Fairness/justice）
* 问责制（Accountability）
* 安全（Safety）
* 解释性/可解释性（Explainability/Interpretability）

**较少/不引用的原则：**

* 自主权（Autonomy）
* 人工智能领域的多样性（Diversity in AI field）
* 举报人保护（Whistleblower protection）
* 关于人工智能风险的公众教育（Public education about AI risks）
* 双重用途（Dual use）
* 政治虐待（Political abuse）
* 社会成本（Social costs）
* 公私伙伴关系（Public–private partnerships）
* 环境成本（Environmental costs）
* 存在的威胁（Existential threats）
* 机器/机器人伦理（Machine/robot ethics）

### 2.3 影响 AI 前进的力量

* 高引用的：更适合 **技术解决方案**
* 参见 *less ‘algorithmic’ ones based in wider social context*
* 反映男性主导领域（包括伦理准则的作者）吗？
* 世界一流大学的教授中有 80％ 是男性
* 也许需要更多的女权主义思维方式？
* 企业资金，例如：AI 研究基金
* 企业权力，例如：Facebook
* 军事支持
* 状态，例如：监视
* 这意味着既可能带来很多正面影响，也可能带来很多负面影响

### 2.4 残酷的竞争

* AI 超级大国：美国、欧盟、中国 $\Longrightarrow$ AI 军备竞赛
* *“快速行动并打破事物”*  参见 **AI4People** 或 **AI4Social good**
* 竞争对手被视为敌人
* 经济逻辑
* **但是：**道德伦理不支持不惜一切代价的竞争
* 道德伦理通常有利于：协作、合作、信任
* 但！道德伦理 “在洲际飞机上扮演自行车刹车的角色”

**然而：**

* 个人道德价值观可能会产生影响
* Google 致力于 Project Maven（人工智能军用无人机）的计算机视觉
* 微软致力于数据科学和 ICE（移民和海关执法）的 AI 的研究，该项目将迫使孩子与父母分离
* 具有技术技能的个人可以产生影响，例如  Joy Buolamwini 和 Timnit Gebru 在种族偏见的面部识别方面的工作

### 2.5 广泛的道德框架

* **功利主义（Utilitarianism）**—— 基于结果（consequence based）
* **义务论（Deontology）**—— 基于规则（rule based）
* **美德伦理（Virtue ethics）**—— 基于品格（character based）
* **护理伦理（Ethics of care）**—— 基于关系（relationship based）

人工智能从业者需要考虑其工作的短期和长期道德伦理影响。

## 3. 伦理学简介

### 3.1 人工智能与道德伦理

* **哲学（Philosophy）**– 终极的 “大” 问题

* **思维哲学（Philosophy of Mind）**

* **道德哲学（Moral Philosophy）**

* **数字伦理（Digital ethics）**
  * 计算机伦理（Computer ethics）
  * 机器人伦理（Robot ethics）
  * 机器伦理（Machine ethics）
  * 数据伦理（Data ethics）
  * 人工智能伦理（AI ethics）

### 3.2 什么是伦理？

* 您认为伦理是什么？

* 伦理学涉及一个大问题：

  > “我们应该如何生活？”
  >
  > —— 苏格拉底《生命的意义》

* 伦理是关于价值观、道德、好与坏的行为、对与错

1. 我应该怎么做？（我应该采取什么行为标准？）
2. 我应该成为什么样的人？

### 3.3 利己主义（Egoism）

* *“我应该只做对我有益的事情”*
* 道德是关于尊重和关注他人

### 3.4 相对主义（Relativism）

* 没有普适的对与错
* 相对主义：对/错只是意味着某种特定文化所认为的对/错
* 例如：人权
* 问题：对/错是那些意思吗？
* 人们可以不同意自己或他人的文化信仰
* 互相说明理由；原因可以是强也可以是弱
* 因此：相对主义者没有表明没有普遍的对与错

### 3.5 伦理中的理性

然而，由于伦理是一个理性的过程，并且对于以下伦理问题，可能存在普适的好与坏，以及对与错的回答：

* 伦理答案并不总是很明确
* 没有符合伦理标准的教科书
* 我们可以自由地彼此不同意
* 我们可以尊重彼此的观点
* 我们可以尊重文化多样性和洞察力
* 苏格拉底：我们可以通过思想开放和与他人对话，更好地了解伦理学并检验我们的伦理信念

### 3.6 为什么要符合伦理？

* 社会期望
* 成为成功的团队合作者
* 获得他人的尊重
* 避免罪恶感并保持正直
* 过充实的生活
* 因为我在乎别人
* 仅因为这是正确的事情
* 因为：“未经检验的生活对于人类来说不值得”

## 4. 伦理框架

### 4.1 伦理框架

1. **功利主义（Utilitarianism）**—— 基于结果（consequence based）
2. **义务论（Deontology）**—— 基于规则（rule based）
3. **美德伦理（Virtue ethics）**—— 基于品格（character based）
4. **关怀伦理（Ethics of care）**—— 基于关系（relationship based）
5. **原则主义（Principlism）**—— 框架 1- 4 的简化集成

| **理论**     | **一些关键元素**                                             |
| ------------ | ------------------------------------------------------------ |
| **功利主义** | 最大化净福利，即伤害（例如痛苦、困苦、损失）和收益（例如快乐、享受、满足）的最佳整体平衡。如果每个人的兴趣相同，那么他们的兴趣就同等重要。 |
| **义务论**   | 遵循关键的道德规则，例如公平行事、避免伤害、友善等。当规则发生冲突时，找出应优先考虑的原则。康德严格版的义务论：永远把人当作目的本身，而不仅仅是手段：永远不要欺骗或剥削他们或破坏他们的自主性。 |
| **美德伦理** | 问一个有智慧和优秀品格（例如公平、善良、慷慨、诚实）的人会做什么。寻找有道德的榜样来解释在特定情况下如何公平、勇敢等。 |
| **关怀伦理** | 查看关系及其上下文。考虑弱势群体、依赖者、边缘化和受压迫者以及责任关系。 想想那些涉及同情、关怀和强烈责任感等情感的回应。 |

我们决策背后的更深层次的价值观，包括人工智能。

伦理理论为我们提供了不同的方式来确定什么是对与错。不同的哲学家会喜欢不同的理论，或者会认为某些理论比其他理论更强大。你不需要决定哪个是最好的理论；但请注意，它们确实提供了确定是非的不同方法，这些方法可能会相互冲突。例如，功利主义者可能认为杀死一个人是一种道德义务，如果这是拯救三个人的唯一方法；而义务论者可能会说，即使可以挽救更多人，违反禁止杀人的道德规则也是错误的。美德伦理学家可能会同意，因为（他们可能会说）一个公正和仁慈的人不会这样做。您要确保，如果您使用多个道德理论来证明一个观点是正确的，那么这些理论实际上并不是在说相反的事情！

理论之间也存在显着的重叠。例如，他们都可以谈论公平、做好事、避免伤害等。但是：他们可能会以不同的方式谈论这些事情。例如，美德伦理告诉我们要从公正、善良、诚实等人那里寻求指导。其他理论也谈论公正等。然而，美德伦理告诉我们，解释这些事情的方式是问一个有美德和良好品格的人会做什么。例如：使用 Northpointe 的 COMPAS 算法来预测累犯是否公平？美德伦理学家会问：那么，一个品德高尚的人会说什么？一个真正公正的人会赞成 COMPAS 吗？他们会希望它被禁止吗？还是改了？（你可能对这个问题给出不同的答案，但重要的是当你使用那个理论时，你遵循美德伦理的建议——对于其他理论也是如此）。

### 4.2 功利主义（Utilitarianism）

* **结果论（Consequentialism）：**仅依照结果来决定行动的正确性
* “最大幸福原则认为：如果某些行为倾向于促进幸福，那么它们在一定程度上是正确的，而如果某些行为违背了幸福，那么它们是错误的”（John Stuart Mill）
* 结果：幸福或者福利
* 利益：危害和利益可以是心理的、身体的、情感的、社会的、经济的、精神的
* 正确的行动：最佳的整体状况
* **最大限度地提高净福利或利益**
* AI：考虑 **所有** 后果
* 他们的宏伟和概率

**功利主义：**它告诉我们最大限度地提高我们行为的良好后果，就最大限度地提高幸福感（减少伤害和促进良好）而言。功利主义（这是一种“后果主义”）说这种最大化的计算是我们应该遵循的唯一道德规则，即使这意味着某些人必须受到伤害才能产生最大的幸福。在计算产生最佳整体净福利的因素时，我们需要考虑所有危害和商品/收益的大小以及所有危害和商品/收益的概率。在这些术语中，任何产生最佳结果的行为都是正确的——所有其他行为都是错误的！功利主义很受欢迎，但有些人反对这意味着如果这可以最大限度地提高净福利，我们就必须不公平或不公正。功利主义者会回应说，公平或正义只是将最好的结果最大化！

### 4.3 义务论（Deontology）

* 基于规则
* 例如：信守诺言、讲真话、公平行事、表达感激之情、不要伤害、做好事、提高自己
* 正确的做法不一定能产生最佳状态
* **绝对命令（Categorical Imperative）：**“永远以自己或他人的身份对待人类，绝不只是作为一种手段，而是总是与目的并驾齐驱”（Immanuel Kant）
* 人的尊严
* 尊重自主权 —— 道德选择者
* 严格或绝对的职责，例如：永远不要故意将无辜者入狱

**义务论：**它告诉我们要遵循一系列规则，例如公平行事、说实话、不杀戮、不欺骗、信守承诺、慷慨解囊、表现出感恩、善良、做错事时要改正。义务论告诉我们要明智地将这些原则应用到我们的行动中，如果它们发生冲突，我们要尽量平衡它们。例如，如果说实话会导致极大的不公平，那么义务论者可能会说我们应该支持 “公平行事” 规则，而忽略 “说实话” 规则。在给定的情况下，确定哪个或哪些规则是最强的，这是一个问题。没有算法可以做到这一点！相反，您需要尽可能地应用规则，并准备好应对挑战。例如，您可以在特定情况下争辩说不诚实相当轻微，而如果非常严重则不公平 —— 反之亦然。

许多道义学家会接受，有时在风险非常高的情况下伤害个人是允许的，例如如果这是拯救数千人的唯一方法，那就去杀一个人。然而，与功利主义不同，义务论说，如果这意味着凌驾于公平行为等重要规则之上，我们就不能只是试图最大化好的结果。

伊曼纽尔·康德有一种特殊的、甚至更为严格的义务论。他说，有些道德规则是绝对的，绝对不能被打破。康德说，我们应该始终把人当作目的本身，而不仅仅是手段（即使是为了好的目的）。这意味着我们永远不能故意伤害或使用某人，即使这是有充分理由的。康德说，我们尤其应该始终尊重他人的自主权（根据自己的价值观做出决定的能力）。可以说，当我们伤害某人并凌驾于他们的自主权时，我们将某人用作手段而不是目的。例如，如果我们对某人撒谎、违背明确的承诺或利用他们的弱点，即使我们的目标是产生其他好的结果，我们也会将某人用作手段而不是目的本身。

### 4.4 美德伦理（Virtue ethics）

* 关注品格：涉及情感和行动的品格
* **美德 (Virtues)：**同情、勇气、正义、仁慈、诚实、善良、感激、自我控制、慈善、忠诚、信任
* **恶习 (Vice)：**不宽容、恶意、鲁莽、自私、盲目忠诚、轻信
* 正确 = 善良的人的行为举止
* 在给定情况下正确的感觉和正确的行动
* 例如 Timnit Gebru 和 Joy Boulamwini：站在大技术领域-呼吁在AI开发中做到公平、透明、多样化
* 公正/公平、诚实、勇气

**美德伦理：**它告诉我们通过问一个有德的人会做什么来判断我们的行为是对还是错 —— 也就是一个慷慨、公正、勇敢、仁慈的人（倾向于善良而不伤害他人）。美德伦理不是告诉我们要最大限度地提高幸福感或简单地咨询和遵守道德规则，而是告诉我们要以榜样为榜样，这些人具有道德上令人印象深刻的品格，他们具有这些美德的性格特征，并始终避免恶习（贪婪、不公平、自私） 、脾气暴躁、鲁莽、懦弱等）并明智地行动。这些人向我们展示了哪些规则是重要的，以及在给定的上下文中应该如何实施它们。例如，有些人会认为像甘地、佛陀、纳尔逊曼德拉等令人印象深刻和聪明的人是我们应该寻求道德指导的人物，例如因为他们勇敢地面对不公正的方式。这样的人（有人说）有勇气、诚实、善良和公平等美德。人工智能的一个例子可能是 Timnit Gebru 与强大的公司对抗以产生更公平的算法。相比之下，也许你会说马克·扎克伯格在运营 Facebook 时并不总是表现出良好的品格！我们还可以考虑书籍/电影等中人物的良好性格。请注意，在 “美德伦理中”，我们不一定需要指出这样的人 —— 我们可以简单地问：“什么才是真正公正、善良、诚实的人？他们在这种情况下会怎么办？”

### 4.5 关怀伦理（Ethics of care）

* **女权伦理（Feminist ethics）**
* 对比：理性主义、抽象原则、严厉的公正、缺乏情绪
* 亲属关系和人际关系 —— 情绪和行为
* 关怀、参与、关爱、承担责任
* 意识到脆弱性和无力感

**关怀伦理：**它告诉我们要审视我们或他人所处的各种关系（父母、家人、同事、同胞、关怀关系、雇主-雇员等）。源自女权主义伦理的关怀伦理说，我们必须特别（尽管不是完全）意识到弱势、处于危险之中、被边缘化或需要帮助的人。我们应该密切关注语境特征，例如历史压迫、隐藏的偏见、权力失衡和依赖关系。例如，妇女、儿童、跨性别者、残疾人、有色人种等往往更容易受到伤害和/或有过压迫或忽视的历史。此外，一些关系涉及权力不平衡 —— 在这里，掌权的一方需要特别注意他们能够剥削或使用权力较小的人的方式。关怀伦理说我们不应该只是遵循抽象的规则，我们还需要利用我们的感觉和情绪。例如，当人们受到不公平对待时，我们可以对脆弱的人感到同情、对他们的关心以及愤慨和愤怒。关怀伦理学说，传统的道德理论（如功利主义和义务论）忽视了情感在伦理学中的重要作用。

### 4.6 原则主义：4 条原则 + 1

源自医学伦理（medical ethics）：

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-06-21-WX20210621-151506%402x.png" width="45%">

**1. 非恶意 (Non-maleficence) —— 不伤害**

* 预测伤害，避免造成伤害，将短期和长期的伤害降到最低

**2. 善行 (Beneficence) —— 做好事**

* 预期短期和长期的良好结果

**3 尊重自主权 (Respect autonomy) —— 尊重人们的价值观、选择、生活计划**

* 了解他人的价值，不要践踏他们的选择，诚实

**4. 公正 (Justice) —— 公平**

* 公平分配利益和损害，公平地进行处理，不要造成不公平的歧视

**4 + 1. 解释性 (Explicability) —— 透明度和问责制**

* 补充四项原则
* 确保那些可能受影响的人对 AI 有足够的了解，并追究相关人员的责任

所有原则都是平等的，不同原则之间需要取得平衡。

## 5. 应用伦理框架

### 5.1 例子：人工智能头带在伦理上是否合理？

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-06-21-WX20210621-152306%402x.png" width="60%">

**AI 头带：**

* BrainCo Focus 头带
* 中国浙江省东部金华市的小学
* 三个传感器，两个在耳朵后面，一个在额头上
* “它使用脑电图（EEG）传感器来测量大脑信号，并使用 AI 算法来传输信号，然后将其转换为实时聚焦水平”
* 监控学生的注意力
* 带上显示的颜色
* 显然，该产品旨在帮助学生通过神经反馈集中注意力
* 数据保存在公司服务器上
* 引起争议，父母反对
* 科技公司是否应该生产这类产品？ 学校是否应该部署这类产品？

### 5.2 功利主义

**结果论的类型：带来最佳结果**

* 正式规则：最大化净福利（效用原则）
* 每个人的兴趣都很重要
* 幅度和概率

**好的结果：**

* 提高注意力
* 更好的教育成果
* 协助老师
* 让父母放心
* 完善 AI 的使用，促进科技进展

**坏的结果：**

* 物理影响
* 学生的焦虑和压力
* 教育成果更差
* 父母压力大
* 它真的有效吗？

### 5.3 义务论

* 基于规则
* 关键规则
* 对学生公平吗？
* 对父母诚实吗？
* **即使产生了整体利益 —— 例如，通过改进AI监控技术并取得科学突破 —— 也并不一定意味着正确。**
* 伊曼纽尔·康德 (Immanuel Kant)：它是否尊重自治并以人为本，而不仅仅是作为手段？

### 5.4 美德伦理

* 向模范善良（品德高尚）的人寻求指导
* 您尊敬的老师对此有何看法？他们会签署吗？
* 这里有哪些美德？
* 例如：诚实、同情、公平、勇气
* 信任：轻信与犬儒主义

### 5.5 关怀伦理

* 关系、情境、关怀反应：养育、爱心、承担责任、认识到脆弱性和无力感
* 假设您是 BrainCo Focus 头带的开发团队的成员，您可能会问：
  * 如果我是这些孩子的父母，我应该如何应对？
  * 开发 BrainCo 头带是否与对这些孩子的照料，养育或爱保持一致？

### 5.6 原则主义（4 + 1原则）

* **1. 非恶意** 和 **2. 善行**
* **3. 尊重自治**
  * 父母
  * 孩子们
  * 隐私 —— 公司存储和拥有的数据
  * 知情同意
* **4. 公正**
  * 旨在改善教育成果 $\Longrightarrow$ 但最终以牺牲孩子利益为代价
* **4 + 1 解释性**
  * 对父母、孩子、老师透明
  * 教育部门、学校、科技公司的责任

### 5.7 总结

* 关于伦理的答案并不总是很明确
* 但是，践行伦理的方法有优劣之分
* 伦理框架：功利主义、义务论、美德伦理、关怀伦理、原则主义
* 所有框架可能都提供了一些东西
* 回答问题时不需要使用每个框架
* 苏格拉底：与他人对话时，我们会质疑自己的假设，聆听和检验自己的想法，从而获得智慧。例如：教程、研讨会

## 6. 推荐阅读

* [*Additional notes for module 3.*](http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-08-03-Additional%20notes%20for%20module%203.pdf)
* [*The Ethics of AI Ethics: An Evaluation of Guidelines.*](http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-08-03-Hagendorff_2020_The%20Ethics%20of%20AI%20Ethics.pdf)
