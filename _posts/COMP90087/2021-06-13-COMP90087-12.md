---
layout:     post   				    # 使用的布局（不需要改）
title:      人工智能伦理 12：总结   	# 标题 
subtitle:   墨尔本大学 COMP90087 课程笔记 #副标题
date:       2021-06-13				# 时间
author:     YEY 						# 作者
header-img: img/post-bg-unimelb.png 	#这篇文章标题背景图片
catalog: true 						# 是否归档
mathjax: true                       # 是否启用 MathJax
tags:								#标签
    - 人工智能伦理
    - COMP90087
    - 课程笔记
---

# Module 12 总结

## 1. 回顾伦理工具

### 1.1 为什么要使用这些工具？

对人工智能伦理进行反思和严谨的思考，以及独立和与该领域研究人员对话的能力。

### 1.2 伦理理论/框架

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-06-25-WX20210625-121355%402x.png" width="100%">

* 功利主义（Utilitarianism）
* 义务论（Deontology）
* 美德伦理（Virtue ethics）
* 关怀伦理（Ethics of care）
* 原则主义（Principlism）

### 1.3 伦理原则

* 行善（Beneficence）
* 无恶意（Nonmaleficence）
* 透明度（Transparency）
* 安全（Safety）
* 问责制（Accountability）
* 公平/公正（Fairness/justice）
* 尊重自主权（Respect for autonomy）
* 隐私（Privacy）
* ……

### 1.4 设计中的伦理指南（Beard & Longstaff）

* 正当性优先（需要伦理反思和讨论）（Ought before can, need for ethical reflection and discussion）
* 非工具主义（康德道义论）（Non-instrumentalism, Kantian deontology）
* 自决（自主）（Self-determination, autonomy）
* 责任（自我问责）（Responsibility, accountability of self）
* 净收益（Net benefit）
* 公平（公正，例如：类似案例类似处理）（Fairness, justice – like cases alike)）
* 可及性（平等）（Accessibility, equity）
* 目的（Purpose）

### 1.5 例子：杀手机器人

自主战斗机器：它们应该被开发吗？ 或者应该停止/禁止它们吗？

可以 *潜在地* 使用每种 **伦理理论/框架** 来 *支持或反对* 杀手机器人。

例如，功利主义：杀手机器人既可以带来好的后果（例如减少士兵死亡）也可以带来坏的后果（例如使国家更有可能开战）等。其他理论也可以类似分析。

**原则和指南** 的应用也类似，例如，问责制：也许民主国家可以对使用杀手机器人承担一定的责任，但流氓国家或恐怖组织呢？

但是，请仔细选择和使用它们：

* 有时以一种方式使用理论或原则可能比以另一种方式使用更好
* 例如，设计一个终结者天网显然不会得到大多数/所有伦理理论的支持！
* 需要 *展示* 您对这些理论/原则的理解
* *详细* 论证这些理论或原则 *如何* 支持您的立场（例如，功利主义：好的和坏的后果的 *证据*；展示如何 *权衡* 它们以使好处最大化等）
* 考虑 *其他* 观点，进行反驳并与之互动

另请参阅 Bietti reading 以获取另一个示例（监视）

## 2. 从伦理清洗到伦理抨击（Bietti, 2020）

阅读：Bietti, E. (2020, January). From ethics washing to ethics bashing: a view on tech ethics from within moral philosophy. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 210-219).

### 2.1 伦理清洗（Ethics washing）

* 错误使用 “伦理” 一词和伦理语言
* 大型科技公司
* 伦理行为的表象而非现实
* 自私自利的使用
* 为放松管制、自我监管或市场驱动的治理进行辩护

* 雇佣伦理哲学家来让自己看起来很好但实际上做的并不多

* 公司的伦理学家可能对他们的言行感到或受到拘束

* 修补圆角 vs. 提出尖锐的、破坏性的问题

  例如：“可以做到并不意味着应该做”，某些 AI 也许本来就不应该被开发出来，而不是事后再去对其算法公平性进行修补

### 2.2 伦理抨击（Ethics bashing）

哲学和伦理被视为：

1. 单纯的沟通策略，以及掩盖不道德行为的形式

2. 对于实践中需要处理的复杂问题，采取单纯的 “象牙塔式” 的智能化（过于抽象、遗漏细节、相关性不足）

3. 反对政治代表和社会组织

### 2.3 固有价值与工具价值
* 固有价值（Intrinsic value）：为了理解自身而值得践行的伦理
* 工具价值（Instrumental value）：将伦理作为改变事物的工具，例如：更好的监管、公司声誉等。
* 不相互排斥！两种价值都很重要
* 伦理/道德哲学：需要理性、公正和质疑的态度 —— 而不是以工具性态度为主

### 2.4 问题

伦理学家应该为谷歌或 Facebook 等大型科技公司工作吗？

他们是否应该准备好冒着失去工作的风险，并遵循自己的良知？

他们是否应该充当公司不良行为的举报人？

### 2.5 其他问题

* 伦理学：能带来什么好处？

* 伦理学是值得践行的吗？

* 伦理准则有用吗？

* 伦理学仅仅是 “在飞机上扮演自行车刹车的角色” 吗？

* **硬性监管（Hard regulation）** 对于确保良好结果和追究人们的责任是否更为重要？

* 是否应该向所有计算机科学家教授伦理学？

## 3. 推荐阅读

* [*From Ethics Washing to Ethics Bashing.*](http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2021-08-05-SSRN-id3513182.pdf)
