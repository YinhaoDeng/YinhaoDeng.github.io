---
layout:     post   				    # 使用的布局（不需要改）
title:      PyTorch 02：张量简介及创建  	# 标题 
subtitle:   PyTorch 学习笔记 #副标题
date:       2020-12-06				# 时间
author:     YEY 						# 作者
header-img: img/post-sample-image04.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
mathjax: true                       # 是否启用 MathJax
tags:								#标签
    - PyTorch
    - 学习笔记
---

# Lecture 02 张量简介及创建

## 1. 张量是什么？
### 1.1 张量是什么？

**张量 (Tensor)** 是一个多维数组 ， 它是标量、向量、矩阵的高维拓展。

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-09-WX20201209-184407%402x.png" width="90%">

常见的灰度图像可以用一个矩阵 (2 维张量) 表示；而 RGB 彩色图像则需要用一个 3 维张量表示 (3 个维度分别表示图像的高度、宽度和 RGB 色彩通道)。

### 1.2 Tensor 与 Variable

Variable 是 `torch.autograd` 中的数据类型，主要用于封装 Tensor，进行 **自动求导**。

* `data`：被包装的 Tensor。
* `grad`：`data` 的梯度。
* `grad_fn`：创建 Tensor 的 Function，是自动求导的关键。
* `requires_grad`：指示是否需要梯度。
* `is_leaf`：指示是否是 (计算图中的) 叶子结点（张量）。

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-09-WX20201209-184916%402x.png" width="38%">

PyTorch 0.4.0 版本开始，Variable 并入 Tensor。

* `dtype`：张量的数据类型，如 `torch.FloatTensor`、`torch.cuda.FloatTensor`。
* `shape`：张量的形状，如 `(64, 3, 224, 224)`。
* `device`：张量所在设备，GPU/CPU，是加速的关键。

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-09-WX20201209-190443%402x.png" width="52%">

可以看到，目前的 Tensor 包含了 8 个主要属性，其中 4 个与数据相关，另外 4 个与梯度求导相关。

PyTorch 主要提供了以下 9 种数据类型：

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-09-WX20201209-191038%402x.png" width="90%">

通常，使用最多的数据类型是 `torch.float32`，常用于卷积层的权重值，或者图像预处理之后都是默认为 32 位的浮点数。另外，`torch.int64` 也用的比较多，通常用 64 位整型来表示图像标签，在计算交叉熵的损失函数时需要注意这点。

## 2. 张量的创建

### 2.1 直接创建

#### `torch.tensor()`

**功能**：从 `data` 创建 `tensor`。

```python
torch.tensor(
    data,
    dtype=None,
    device=None,
    requires_grad=False,
    pin_memory=False
)
```

**主要参数**：

* `data`：数据，可以是 `list` 或者 `numpy`。
* `dtype`：数据类型，默认与 `data` 的一致。
* `device`：所在设备，`cuda` 或者 `cpu`。
* `requires_grad`：是否需要梯度。
* `pin_memory`：是否存于锁页内存，与转换效率有关，通常设为 `False`。

#### `torch.from_numpy(ndarray)`

**功能**：从 `numpy` 创建 `tensor`。

**注意事项**：从 `torch.from_numpy` 创建的 `tensor` 与原 `ndarray` **共享内存**，当修改其中一个的数据，另外一个也将会被改动。

<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-09-WX20201209-201008%402x.png" width="50%">

### 2.2 依据数值创建

#### `torch.zeros()`

**功能**：依 `size` 创建全 0 张量。

```python
torch.zeros(
    *size,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `size`：张量的形状，如 `(3, 3)`、`(3, 224, 224)`。
* `out`：输出的张量，即将生成的全 0 张量赋值给 `out` 参数的变量。
* `layout`：内存中布局形式，有 `strided`、`sparse_coo` 等。通常采用默认的 `strided`；如果涉及稀疏张量可能需要设置为 `sparse_coo` 以提升读取效率。
* `device`：所在设备，gpu / cpu。
* `requires_grad`：是否需要梯度。

#### `torch.zeros_like()`

**功能**：依 `input` 形状创建全 0 张量。

```python
torch.zeros_like(
    input,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `intput`：创建与 `input` 同形状的全 0 张量。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.ones()`

**功能**：依 `size` 创建全 1 张量。

```python
torch.ones(
    *size,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `size`：张量的形状。
* `out`：输出的张量。
* `layout`：内存中布局形式。
* `device`：所在设备，gpu / cpu。
* `requires_grad`：是否需要梯度。

#### `torch.ones_like()`

**功能**：依 `input` 形状创建全 1 张量。

```python
torch.ones_like(
    input,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `intput`：创建与 `input` 同形状的全 1 张量。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.full()`

**功能**：依 `size` 创建全部值均为 `fill_value` 的张量。

```python
torch.full(
    size,
    fill_value,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `size`：张量的形状，如 `(3, 3)`。
* `fill_value`：张量的值。

#### `torch.full_like()`

**功能**：依 `input` 形状创建指定数据的张量。

```python
torch.full_like(
    input,
    fill_value,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `intput`：创建与 `input` 同形状的全部值均为 `fill_value` 的张量。
* `fill_value`：张量的值。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.arange()`

**功能**：创建等差的 1 维张量。

```python
torch.arange(
    start=0,
    end,
    step=1,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `start`：数列起始值。
* `end`：数列 “结束值”（无法取到）。
* `step`：数列公差，默认为 1。

**注意事项**：数值区间为 `[start, end)`。

#### `torch.linspace()`

**功能**：创建均分的 1 维张量。

```python
torch.linspace(
    start,
    end,
    steps=100,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `start`：数列起始值。
* `end`：数列结束值。
* `steps`：数列长度。

**注意事项**：数值区间为 `[start, end]`。

#### `torch.logspace()`

**功能**：创建对数均分的 1 维张量。

```python
torch.logspace(
    start,
    end,
    steps=100,
    base=10.0,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `start`：数列起始值。
* `end`：数列结束值。
* `steps`：数列长度。
* `base`：对数函数的底，默认为 10。

**注意事项**：长度为 `steps`，底为 `base`。

#### `torch.eye()`

**功能**：创建单位对角矩阵（2 维张量）。

```python
torch.eye(
    n,
    m=None,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `n`：矩阵行数。
* `m`：矩阵列数。

**注意事项**：默认为方阵。

### 2.3 依概率分布创建张量

#### `torch.normal()`

**功能**：生成正态分布（高斯分布）。

```python
# mean 和 std 中至少有一个是张量，从不同的正态分布中采样得到，无需指定 size。
torch.normal(
    mean,
    std,
    out=None
)

# mean 和 std 均为标量，从相同的正态分布中采样得到，需要指定 size。
torch.normal(
    mean,
    std,
    size,
    out=None
)
```

**主要参数**：

* `mean`：均值。
* `std`：标准差。

**四种模式**：

* `mean` 为 **标量**，`std` 为 **标量**。
* `mean` 为 **标量**，`std` 为 **张量**。
* `mean` 为 **张量**，`std` 为 **标量**。
* `mean` 为 **张量**，`std` 为 **张量**。

#### `torch.randn()`

**功能**：依 `size` 生成 **标准正态分布** 张量。

```python
torch.randn(
    *size,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `size`：张量的形状。
* `out`：输出的张量。
* `layout`：内存中布局形式。
* `device`：所在设备，gpu / cpu。
* `requires_grad`：是否需要梯度。

#### `torch.randn_like()`

**功能**：依 `input` 生成 **标准正态分布** 张量。

```python
torch.randn_like(
    input,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `intput`：创建与 `input` 同形状的标准正态分布张量。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.rand()`

**功能**：在区间 [0, 1) 上，依 `size` 生成 **均匀分布** 张量。

```python
torch.rand(
    *size,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `size`：张量的形状。
* `out`：输出的张量。
* `layout`：内存中布局形式。
* `device`：所在设备，gpu / cpu。
* `requires_grad`：是否需要梯度。

#### `torch.rand_like()`

**功能**：在区间 [0, 1) 上，依 `input` 生成 **均匀分布** 张量。

```python
torch.rand_like(
    input,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `intput`：创建与 `input` 同形状的 [0, 1) 均匀分布张量。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.randint()`

**功能**：区间 [low, high) 上，依 `size` 生成 **整数均匀分布** 张量。

```python
torch.randint(
    low=0,
    high,
    size,
    out=None,
    dtype=None,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `low`：区间下界。
* `high`：区间上界。
* `size`：张量的形状。
* `out`：输出的张量。
* `layout`：内存中布局形式。
* `device`：所在设备，gpu / cpu。
* `requires_grad`：是否需要梯度。

#### `torch.randint_like()`

**功能**：在区间 [low, high) 上，依 `input` 生成 **整数均匀分布** 张量。

```python
torch.rand_like(
    low=0,
    high,
    input,
    dtype=None,
    layout=None,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `low`：区间下界。
* `high`：区间上界。
* `intput`：创建与 `input` 同形状的 [low, high) 整数均匀分布张量。
* `dtype`：数据类型。
* `layout`：内存中布局形式。

#### `torch.randperm()`

**功能**：生成生成从 0 到 n-1 的随机排列张量，通常用来生成乱序的索引。

```python
torch.randperm(
    n,
    out=None,
    dtype=torch.int64,
    layout=torch.strided,
    device=None,
    requires_grad=False
)
```

**主要参数**：

* `n`：张量的长度。

#### `torch.bernoulli()`

**功能**：以 `input` 为概率，生成伯努力分布（0-1 分布，两点分布）。

```python
torch.bernoulli(
    input,
    *,
    generator=None,
    out=None
)
```

**主要参数**：

* `input`：概率值。

## 3. 总结

本节课介绍了 PyTorch 中的数据结构 —— 张量 (Tensor)，它是 PyTorch 中最基础的概念，其参与了整个运算过程。这里我们介绍了张量的概念和属性，如 `data`、`device`、`dtype` 等，并介绍了张量的基本创建方法，如直接创建、依数值创建和依概率分布创建等。

下节内容：张量操作与线性回归
